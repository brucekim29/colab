{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brucekim29/colab/blob/main/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC_%EA%B8%B0%EC%B4%88_Reuters_News_Classification_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # !sudo apt-get install -y fonts-nanum\n",
        "  # !sudo fc-cache -fv\n",
        "  # !rm ~/.cache/matplotlib -rf\n",
        "\n",
        "  # 이 셀 실행후, 런타임 다시시작\n",
        "  "
      ],
      "metadata": {
        "id": "sfYcefdBp5Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou9Oma8wK93q"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.rc('font', family='NanumBarunGothic')     # 한글 폰트\n",
        "# import matplotlib as mpl\n",
        "# mpl.rc('axes', unicode_minus=False)           # 유니코드 \"-\" sign\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.datasets import reuters\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global constants and hyper-parameters\n",
        "MY_SAMPLE = 2947\n",
        "NUM_CLASS = 46          # Classification class\n",
        "MY_NUM_WORDS = 2000     # number of words in dictionary\n",
        "\n",
        "\n",
        "MY_HIDDEN = 512         # \n",
        "MY_DROPOUT = 0.5        # Dropout rate : temporarily dropout given rate of cell's outputs to \"0\" : like Regularization\n",
        "\n",
        "MY_EPOCH = 10\n",
        "MY_BATCH = 64"
      ],
      "metadata": {
        "id": "OKkyP9HFLXzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# DATABASE SETTING #\n",
        "####################\n",
        "# there are 46 news categories in reuters DB\n",
        "labels = ['cocoa','grain','veg-oil','earn','acq','wheat','copper',\n",
        "          'housing','money-supply','coffee','sugar','trade','reserves', \n",
        "          'ship','cotton','carcass','crude','nat-gas','cpi','money-fx',\n",
        "          'interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "          'strategic-metal','livestock','retail','ipi','iron-steel',\n",
        "          'rubber','heat','jobs','lei','bop','zinc','orange',\n",
        "          'pet- chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "metadata": {
        "id": "yMUJFzAsMF4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print shape information\n",
        "def show_shape():\n",
        "  print('\\n== DB SHAPE INFO ==')\n",
        "  print('X_train shape = ', X_train.shape)\n",
        "  print('X_test shape = ', X_test.shape)\n",
        "  print('Y_train shape = ', Y_train.shape)\n",
        "  print('Y_test shape = ', Y_test.shape) \n",
        "  print()"
      ],
      "metadata": {
        "id": "CQ88jndsMktS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the DB and print shape info\n",
        "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = MY_NUM_WORDS, test_split = 0.3)\n",
        "\n",
        "show_shape()"
      ],
      "metadata": {
        "id": "S37tReOSMq80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16708adf-f2d2-41cb-da31-298b5b07638f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n",
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859,)\n",
            "X_test shape =  (3369,)\n",
            "Y_train shape =  (7859,)\n",
            "Y_test shape =  (3369,)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pWrke2Bm3f6",
        "outputId": "66123a61-bd83-4666-c290-9a915613d113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# statistics on how many articles per category in the train DB\n",
        "# numpy unique is useful in this case\n",
        "print('\\n== TRAIN DATA CONTENT INFO ==')\n",
        "unique, counts = np.unique(Y_train, return_counts = True)\n",
        "for i in range(len(unique)):\n",
        "  print(unique[i], labels[i], \"=\", counts[i])"
      ],
      "metadata": {
        "id": "kwKoV3cdMyhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6caf2c2-a737-4afb-ed71-9be6622c2ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== TRAIN DATA CONTENT INFO ==\n",
            "0 cocoa = 50\n",
            "1 grain = 378\n",
            "2 veg-oil = 66\n",
            "3 earn = 2769\n",
            "4 acq = 1701\n",
            "5 wheat = 14\n",
            "6 copper = 39\n",
            "7 housing = 15\n",
            "8 money-supply = 126\n",
            "9 coffee = 93\n",
            "10 sugar = 114\n",
            "11 trade = 337\n",
            "12 reserves = 40\n",
            "13 ship = 149\n",
            "14 cotton = 18\n",
            "15 carcass = 19\n",
            "16 crude = 387\n",
            "17 nat-gas = 33\n",
            "18 cpi = 59\n",
            "19 money-fx = 475\n",
            "20 interest = 238\n",
            "21 gnp = 91\n",
            "22 meal-feed = 10\n",
            "23 alum = 36\n",
            "24 oilseed = 56\n",
            "25 gold = 77\n",
            "26 tin = 18\n",
            "27 strategic-metal = 13\n",
            "28 livestock = 43\n",
            "29 retail = 19\n",
            "30 ipi = 38\n",
            "31 iron-steel = 34\n",
            "32 rubber = 30\n",
            "33 heat = 9\n",
            "34 jobs = 43\n",
            "35 lei = 10\n",
            "36 bop = 46\n",
            "37 zinc = 17\n",
            "38 orange = 16\n",
            "39 pet- chem = 20\n",
            "40 dlr = 32\n",
            "41 gas = 28\n",
            "42 silver = 10\n",
            "43 wpi = 19\n",
            "44 hog = 10\n",
            "45 lead = 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gaL6dV50M7J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# my_array = [1, 1, 2, 2, 2, 3]\n",
        "# unique, count = np.unique(my_array, return_counts = True)\n",
        "\n",
        "# # print the result\n",
        "# print(unique)\n",
        "# print(count)"
      ],
      "metadata": {
        "id": "dk48PHbRM4Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique, count = np.unique(Y_train, return_counts=True)\n",
        "print(Y_train)    # 7859\n",
        "print(unique)     # Category\n",
        "print(count)      # records per category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjtNNu1WnXfs",
        "outputId": "496cacb0-6c4b-4bc8-b914-c04a8ca6a2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  4  3 ...  4 16  3]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
            "[  50  378   66 2769 1701   14   39   15  126   93  114  337   40  149\n",
            "   18   19  387   33   59  475  238   91   10   36   56   77   18   13\n",
            "   43   19   38   34   30    9   43   10   46   17   16   20   32   28\n",
            "   10   19   10   14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the same statistics visually\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.figure(1)\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.hist(Y_train, bins='auto')\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Number of occurrences\")\n",
        "plt.title(\"Train data\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.hist(Y_test, bins='auto')\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Number of occurrences\")\n",
        "plt.title(\"Test data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-nV-bI_mNExt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "87d5fa68-beba-4994-8aef-ed6e91bce0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample data in its raw format\n",
        "print('\\n== SAMPLE ARTICLE (RAW) ==')\n",
        "print(\"article #\", MY_SAMPLE)\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])\n",
        "print(\"number of words\", len(X_train[MY_SAMPLE]))\n",
        "print(X_train[MY_SAMPLE])\n",
        "\n",
        "# python dictionary: word -> index\n",
        "# zero index is not used\n",
        "word_to_id = reuters.get_word_index()\n",
        "print('\\n== DICTIONARY INFO ==')\n",
        "print(\"There are\", len(word_to_id) + 1, \"words in the dictionary.\")\n",
        "print('The index of \"the\" is', word_to_id['the'])"
      ],
      "metadata": {
        "id": "NCct_CMPNIXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed74722-c854-4648-b918-9967933b5ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (RAW) ==\n",
            "article # 2947\n",
            "category 4 acq\n",
            "number of words 61\n",
            "[1, 2, 1229, 81, 8, 16, 515, 25, 270, 5, 4, 2, 1229, 111, 267, 7, 73, 2, 2, 7, 108, 13, 80, 1448, 28, 365, 12, 11, 15, 1986, 2, 69, 158, 18, 1296, 1275, 7, 2, 1627, 2, 2, 4, 393, 374, 1229, 323, 5, 2, 1229, 7, 2, 9, 25, 2, 473, 936, 4, 49, 8, 17, 12]\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n",
            "\n",
            "== DICTIONARY INFO ==\n",
            "There are 30980 words in the dictionary.\n",
            "The index of \"the\" is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python dictionary: index -> word\n",
        "# this is the opposite to word_to_id dictionary\n",
        "id_to_word = {}\n",
        "for key, value in word_to_id.items():\n",
        "  id_to_word[value] = key"
      ],
      "metadata": {
        "id": "fwaJEa8GNT4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to translate the sample review\n",
        "# we use python dictionary get() function\n",
        "# it returns \"???\" if the ID is not found\n",
        "# index is subtracted by 3 to handle first 3 special characters\n",
        "#   index 0 is for padding (= filling empty space)\n",
        "#   index 1 is for indicating the beginning of a review\n",
        "#   index 2 is for dropped word (= out of bound)\n",
        "# we use python list and join() function to concatenate the words"
      ],
      "metadata": {
        "id": "fH2_oAl6NXW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoding():\n",
        "  decoded = []\n",
        "  for i in X_train[MY_SAMPLE]:\n",
        "    word = id_to_word.get(i - 3, \"???\")\n",
        "    decoded.append(word)\n",
        "\n",
        "  print('\\n== SAMPLE ARTICLE (DECODED) ==')\n",
        "  print(\" \".join(decoded))\n",
        "  \n",
        "decoding()\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])"
      ],
      "metadata": {
        "id": "meJ0vAPXNhAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1c0186-f365-4e11-ebeb-df7bc8466635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (DECODED) ==\n",
            "??? ??? telephone corp said it completed its acquisition of the ??? telephone co based in new ??? ??? in exchange for stock valued at 26 3 mln dlrs enterprises ??? about 16 000 access lines in ??? county ??? ??? the third operating telephone subsidiary of ??? telephone in ??? and its ??? largest overall the company said reuter 3\n",
            "category 4 acq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will NOT do padding (as in movie review classification)\n",
        "# instead we will do tokenization for the inputs\n",
        "# we get a numpy array of size MY_NUM_WORDS for each input \n",
        "# the entries are integer counts \n",
        "# the resulting matrix is very big\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# for i in range(10):\n",
        "#   print(len(X_train[i]))\n",
        "\n",
        "Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "\n",
        "print('before:', X_train[0])\n",
        "print('number before:', len(X_train[0]))\n",
        "X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "print('after:', X_train[0])\n",
        "print('number after:', len(X_train[0]))\n",
        "\n",
        "X_test = Tok.sequences_to_matrix(X_test, mode = 'count')"
      ],
      "metadata": {
        "id": "21DXQk4-Nt0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8994c2b0-b19e-4c93-f0ab-530fa73b5021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "number before: 87\n",
            "after: [0. 1. 4. ... 0. 0. 0.]\n",
            "number after: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "# X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "# X_test = Tok.sequences_to_matrix(X_test, mode = 'count’)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (TOKENIZED INPUT) ==')\n",
        "sample = X_train[MY_SAMPLE]\n",
        "print(*sample, sep = ' ')\n",
        "print(\"Array size:\", len(sample))\n",
        "print(\"Sum of entries:\", np.sum(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6IvUSlAuxkw",
        "outputId": "ee129c35-6e7e-4eed-cb3b-948a61b7eafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (TOKENIZED INPUT) ==\n",
            "0.0 1.0 11.0 0.0 3.0 2.0 0.0 4.0 2.0 1.0 0.0 1.0 2.0 1.0 0.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "Array size: 2000\n",
            "Sum of entries: 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output reshaping using one-hot encoding\n",
        "# from keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train, NUM_CLASS)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASS)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==')\n",
        "sample = Y_train[MY_SAMPLE]\n",
        "print(sample)\n",
        "print(\"Array size:\", len(sample))\n",
        "\n",
        "show_shape()\n"
      ],
      "metadata": {
        "id": "sOnatkWcN8Z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95d1c50-1b07-4a80-fe29-c16aac7e4f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n",
            "Array size: 46\n",
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859, 2000)\n",
            "X_test shape =  (3369, 2000)\n",
            "Y_train shape =  (7859, 46, 46)\n",
            "Y_test shape =  (3369, 46, 46)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "# MODEL BUILDING AND TRAINING #\n",
        "###############################\n",
        "# build a keras sequential model of our DNN\n",
        "# softmax is needed for multi-class classification\n",
        "model = Sequential()\n",
        "model.add(Dense(units=MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))\n",
        "# model.add(Dense(MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))  => have to give Tuple, eg (MY_NUM_WORDS,)\n",
        "# model.add(Activation('relu'))       # later comment this out or use others, \n",
        "model.add(Dropout(MY_DROPOUT))\n",
        "model.add(Dense(NUM_CLASS))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xapmZb7pN_ZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ddcd4cd-51cc-4464-bcd7-a82a90186979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 512)               1024512   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 46)                23598     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 46)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,048,110\n",
            "Trainable params: 1,048,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction using the model\n",
        "# shape needs to change from (2000,) to (1, 2000)\n",
        "def ask_question():\n",
        "  sample = X_train[MY_SAMPLE]\n",
        "  sample = sample.reshape(1, sample.shape[0])\n",
        "  pred = model.predict(sample, verbose = 0)\n",
        "  guess = np.argmax(pred)\n",
        "  answer = np.argmax(Y_train[MY_SAMPLE])\n",
        "  \n",
        "  print('\\n== SAMPLE QUESTION ==')\n",
        "  print(\"My guess for sample article:\", guess, labels[guess])\n",
        "  print(\"The answer is:\", answer, labels[answer]) \n",
        "  print()\n",
        "\n",
        "ask_question()"
      ],
      "metadata": {
        "id": "_BtHybqwOJYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88001d29-968b-4e5e-8a15-cf06c3f8601a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE QUESTION ==\n",
            "My guess for sample article: 39 pet- chem\n",
            "The answer is: 4 acq\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training and saving\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = MY_EPOCH, batch_size = MY_BATCH, verbose = 1)\n",
        "model.save('chap2.h5')"
      ],
      "metadata": {
        "id": "gXNO6YchOQpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16f3acb-c43d-4c55-f15d-4ce7a3a1b2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "123/123 [==============================] - 5s 29ms/step - loss: 1.5951 - accuracy: 0.6814 - val_loss: 1.0906 - val_accuracy: 0.7709\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 3s 27ms/step - loss: 0.8248 - accuracy: 0.8166 - val_loss: 0.9339 - val_accuracy: 0.7964\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.5725 - accuracy: 0.8693 - val_loss: 0.8737 - val_accuracy: 0.8172\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.4284 - accuracy: 0.8997 - val_loss: 0.8846 - val_accuracy: 0.8151\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.3455 - accuracy: 0.9164 - val_loss: 0.8869 - val_accuracy: 0.8172\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2802 - accuracy: 0.9328 - val_loss: 0.9425 - val_accuracy: 0.8035\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2472 - accuracy: 0.9369 - val_loss: 0.9640 - val_accuracy: 0.8071\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2291 - accuracy: 0.9429 - val_loss: 0.9888 - val_accuracy: 0.8115\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2129 - accuracy: 0.9457 - val_loss: 1.0073 - val_accuracy: 0.8065\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.1994 - accuracy: 0.9508 - val_loss: 1.0228 - val_accuracy: 0.8109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# MODEL EVALUATION #\n",
        "####################\n",
        "# evaluate the model and calculate loss and accuracy\n",
        "score = model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "print('Prediction for the first news: ', pred[0])\n",
        "print(np.argmax(pred[0])) \n",
        "print('Answer: ', Y_test[0])\n",
        "print(labels[np.argmax(Y_test[0])]) \n",
        "\n",
        "\n",
        "# ask_question()"
      ],
      "metadata": {
        "id": "A6jJWOAwObWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2124249b-e9ec-433e-af0f-94896fc16e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 6ms/step - loss: 1.0228 - accuracy: 0.8109\n",
            "Test loss: 1.022796630859375\n",
            "Test accuracy: 0.8109230995178223\n",
            "Prediction for the first news:  [3.22900496e-06 1.41694851e-04 1.13677243e-05 9.97722089e-01\n",
            " 1.53637506e-04 1.42586930e-06 2.01378793e-06 9.34992477e-06\n",
            " 1.30355897e-04 1.86532270e-05 6.99617885e-05 1.09929169e-04\n",
            " 1.29409556e-04 1.09581044e-04 5.39884695e-06 1.07686526e-06\n",
            " 4.89228754e-04 6.94056507e-06 1.18522366e-05 3.15230456e-04\n",
            " 2.58561951e-04 8.92716998e-05 4.48833407e-06 3.36628386e-06\n",
            " 3.00458578e-05 7.71187570e-06 7.15408021e-07 2.67980369e-07\n",
            " 6.73027353e-06 1.74658499e-06 3.38306963e-05 1.38831956e-06\n",
            " 4.54773544e-05 1.93201254e-06 1.01185724e-05 3.21419435e-07\n",
            " 1.82864424e-05 2.13436397e-06 1.88927006e-05 8.74327100e-07\n",
            " 9.56531858e-06 4.34908907e-06 1.16170031e-06 4.18211903e-06\n",
            " 2.18518622e-07 1.92102038e-06]\n",
            "3\n",
            "Answer:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "earn\n"
          ]
        }
      ]
    }
  ]
}